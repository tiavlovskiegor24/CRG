#+STARTUP: indent

Managing my work at CRG 


* Task log 

** March 17

*** Fri 10
SCHEDULED: <2017-03-10 Fri>

**** TODO Only leave '_r' scores, drop the rest      :bhive:ds_processing:
**** TODO Moving the scalling of features to the DS preprocessing stage :bhive:ds_processing:ml_inputs:
move the issue to the feature_type processing [[file:feature_types.py][rules]] 
**** TODO Think through more discreet handling of samples with Nans :bhive:ds_processing:
***** DONE for example leave those samples which have Nan for distance features
CLOSED: [2017-03-10 Fri 17:25]
substituting distance Nan with 10*max distance value in dataset
quivalent to "not on this chromosome"

***** DONE move the issue to the feature_type processing [[file:feature_types.py][rules]] 
CLOSED: [2017-03-10 Fri 17:27]
feature type preprocessing removes certain Nans (using rules) and leaves the others 
untouched thus allowing the entire sample to be removed from the dataset
After feature_type preproicessing all the samples with Nans are removed befor passing
them to machine learning 

****** TODO Consider not removing samples with Nans but masking them instead
SCHEDULED: <2017-03-13 Mon>
simply store the indices of Nan samples which will not be passed to ml optimization


**** TODO Create Adaboost pipeline                     :bhive:ml_pipeline:
**** TODO Add gradient boosting to ML_pipeline
**** TODO create control file for the form_full_dataset and prepare_ML_inputs routines 
**** TODO Consider changing the present feature type mapping in dataset :ds_processing:
For example check for present feature_types by looking through dataset column names and
checking "_? _" segments of the name the feature type id look up table
**** TODO Include categorical feature type into [[file:feature_types.py][our feature dictionary]]
*** TODO Consider not dropping rows of columns of dataset for ML_inputs but creating masks
SCHEDULED: <2017-03-13 Mon>



* BHIVE (archive)** Analysis
*** HIV expression prediciton
**** TODO Run SVMs
**** TODO Run RF
**** TODO Run AdaBoost
**** TODO Run gradient boosting



** Machine Learning Pipeline
*** DONE Create SVM pipeline function 
*** DONE Test SVM pipeline function
    Seems to be working


** Dataset processing
*** DONE drop features
*** DONE Split into train and test and save to files
*** DONE count number of samples with NaNs
    Number of samples with Nan is 433
    For now I simply deleted those samples

**** DONE remove Nans from the data set and train on those 

*** DONE [#C] create ML_inputs namedtuple rather then dictionary
*** DONE [#A] extract and store indices of different features types in ML_inputs tuple
*** DONE [#A] apply log1p to the distance values



** Feature File processing
*** DONE Finish up feature file to full array routine
*** DONE finish off write feature file


** Hi-C matrix features
*** DONE fix GMFPT feature writing to file
*** DONE check row sum feature writting to file
*** DONE check decay constant writting to file
*** DONE compute gmfpt 
